<!DOCTYPE html>
<!-- saved from url=(0033)https://QicongXie.github.io/end2endvc/ -->
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <!-- Begin Jekyll SEO tag v2.7.1 -->
  <title>HiGNN-TTS</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="TODO: title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">
  <!-- End Jekyll SEO tag -->

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="style.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
    <!-- <h1 class="project-name">Demo PAGE</h1> -->
    <!-- <h2 class="project-tagline"></h2> -->


  </section>

  <section class="main-content">
    <h1 id="">
      <center>HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for Expressive Long-form TTS</center>
    </h1>

    <h3 id="">
      <center>Blind</center>
      <!-- <center>Ziqian Ning<sup>1, 2</sup>, Yuepeng Jiang<sup>1</sup>, Pengcheng Zhu<sup>2</sup>, Jixun Yao<sup>1</sup>, Shuai Wang<sup>3</sup>, Lei Xie<sup>1</sup>, Mengxiao Bi<sup>2</sup></center> -->
      <center>Blind</center>
      <!-- <center><sup>1</sup>Audio, Speech and Language Processing Group (ASLP@NPU), School of Computer Science, Northwestern Polytechnical University, Xi'an, China</center>
      <center><sup>2</sup>Fuxi AI Lab, NetEase Inc., Hangzhou, China</center>
      <center><sup>3</sup>Shanghai Jiao Tong University, Shanghai, China</center> -->
    </h3>
    <!-- <center>Accepted by INTERSPEECH 2023</center> -->


    <br><br>
    <h2 id="abstract">1. Abstract<a name="abstract"></a></h2>
    <p>Recent advances in text-to-speech, particularly those based on Graph Neural Networks (GNNs), have significantly improved the expressiveness of short-form synthetic speech. However, generating human-parity long-form speech with high dynamic prosodic variations is still challenging. To address this problem, we expand the capabilities of GNNs with a hierarchical prosody modeling approach, named HiGNN-TTS. Specifically, we add a virtual global node in the graph to strengthen the interconnection of word nodes and introduce a contextual attention mechanism to broaden the prosody modeling scope of GNNs from intra-sentence to inter-sentence. Additionally, we perform hierarchical supervision from acoustic prosody on each node of the graph to capture the prosodic variations with a high dynamic range. Ablation studies show the effectiveness of HiGNN-TTS in learning hierarchical prosody. Both objective and subjective evaluations demonstrate that HiGNN-TTS significantly improves the naturalness and expressiveness of long-form synthetic speech.</p>

    <table frame=void rules=none>
      <tr>
        <center><img src='raw/fig/global.png' width="60%"></center>
      </tr>
      <tr>
      </tr>
    </table>
    <br><br>


    <h2>2. Demos <a name="Comparison"></a></h2>
    <ul>
      <!-- <li>Bottomline: Replace all convolution layers in the backbone model [1] with the causal version to create a naïve streaming implementation.</li>
      <li>IBF-VC: Reinplement [2] using the backbone model.</li>
      <li>Topline: Use the unmodified Backbone model which leverage full-context, but input BNF is extracted from a streaming ASR encoder.</li>
      <li>DualVC-nonstreaming: Non-streaming mode of our proposed DualVC.</li>
      <li>DualVC-streaming: Streaming mode of our proposed DualVC.</li> -->

      <!-- <li>SF1 and SM1: source speakers</li>
      <li>IDF1, IDM1, CDF1 and CDM1: target speakers</li> -->
    </ul>

    <h3>2.1. Short Sentence</h3>
    <table>
      <tbody id="tbody_short">
      </tbody>
    </table>

    <h3>2.2. Long Sentence</h3>

    <table>
      <tbody id="tbody_long">
      </tbody>
    </table>

</html>

<script type="" text/javascript>
  function short_form() {
    let scenes = [
      ["DB_19M_000033_0007", "褚师弟，承让承让，伤得不厉害吗？"],
      ["DB_19M_000121_0001", "短话音未了，一连声的悲凄苦笑，突然发自仁立蔷薇坟前的玄衫女子口中，宛如空山鹃位、巫峡猿啼，令人闻直心酸。"],
      ["DB_19M_000167_0007", "这表示他们并不怕冷。他们只是在等候着、磨时间。等一个人，或是等一件待做的事情。"],
      ["DB_26F_010036_0010", "现在不要问，只问你能不能做到？”“只要他有该杀之罪，我定能做到。"],
      ["DB_26F_010041_0005", "三个人仿佛犯了大罪似地连忙跪下，齐声说：“弟子知罪。"],
      ["DB_26F_020022_0032", "收拾得差不多了，她哭笑不得地看着自己沾了很多纸屑的浅蓝色衬衫，世界地图一样狼狈。"]
    ]
    let models = ["TACE", "HCE", "FS2BERT", "HiGNN-TTS"]
    let short_data = `
        <tr>
          <td style="text-align: center; width: 150px;" rowspan=1><strong>Text<strong></td>
        `
    for (const id in models) {
      model = models[id]
      short_data += '<td style="text-align: center; width: 150px;" rowspan=1><strong>' + model + '<strong></td>'
    }
    short_data += `</tr>`
    
    for (let x in scenes) {
      let scene = scenes[x]
      let file = scene[0]
      let text = scene[1]
      let scene_data = ""

      scene_data += '<tr>'
      scene_data += '<td style="text-align: center; width: 150px;" rowspan=1>' + text + '</td>'
      for (let z in models) {
        let model = models[z]
        scene_data += '<td style="text-align: center"><audio style="width: 150px;" controls="" src="' + './raw/samples/' + model + '/' + file + '.wav' + '"></audio></td>'
        
      }
      scene_data += '</tr>'
      short_data += scene_data
    }
    return short_data
  }

  function long_form(params) {
    let scenes = [
      ["long1", "照说年纪不大，可是满脸皱纹深陷，却胜似七八十岁老翁，身穿蓝布直缀，颈中挂着个婴儿所用的锦缎围延，围延上绣著幅花猫扑蝶图，已然陈旧破烂。“这怪人在这儿坐了老半天啦，怎麽动也不动？”,“别叫怪人，要叫“老伯伯”。你叫他怪人，他要生气的。”,“他还不怪吗？这麽老了，头颈里却挂了个围延。他生了气，要是胡子都翘了起来，那才好看呢。”从小舟中拿起一个莲蓬，往那人头上掷去。小舟与那怪客相距数丈，陆无双年纪虽小，手上劲力竟然不弱，这一掷也是甚准。“表妹！”待要阻止，已然不及，只见那莲蓬迳往怪客脸上飞去。那怪客头一仰，已咬住莲蓬，也不伸手去拿，舌头卷处，咬住莲蓬便大嚼起来。五个少女见他竟剥不出莲子，也不怕苦涩，就这麽连瓣连衣的吞吃，"],
      ["long2", "洛秩终于长舒了一口气，把目光移向右侧的玻璃，表情放松而冷漠。北京秋天的晚上很有些萧索，烤肉店内外的温差让窗子上结起了密密的水珠。洛秩试探性地拿起了一杯酒，一口灌下。大家都是不被爱的人，自己没那么彪悍勇敢，只能喝酒略表敬意。世界上总有那么一种人，对于庸庸碌碌的普通人来说，他们的存在简直是一种讽刺。比如盛淮南。“对了，你跟他前女友是同班同学吧？”洛秩吓了一跳，本以为对面的人已经睡死了。"],
    ]
    let models = ["TACE", "HCE", "FS2BERT", "HiGNN-TTS"]
    let long_data = `
        <tr>
          <td style="text-align: center; width: 150px;" rowspan=1><strong>Text<strong></td>
        `
    for (const id in models) {
      model = models[id]
      long_data += '<td style="text-align: center; width: 150px;" rowspan=1><strong>' + model + '<strong></td>'
    }
    long_data += `</tr>`
    
    for (let x in scenes) {
      let scene = scenes[x]
      let file = scene[0]
      let text = scene[1]
      let scene_data = ""

      scene_data += '<tr>'
      scene_data += '<td style="text-align: center; width: 150px;" rowspan=1>' + text + '</td>'
      for (let z in models) {
        let model = models[z]
        scene_data += '<td style="text-align: center"><audio style="width: 150px;" controls="" src="' + './raw/samples/' + model + '/' + file + '.wav' + '"></audio></td>'
        
      }
      scene_data += '</tr>'
      long_data += scene_data
    }
    return long_data
  }

  window.onload = function () {
    document.getElementById('tbody_short').innerHTML = short_form()
    document.getElementById('tbody_long').innerHTML = long_form()
  }
</script>

